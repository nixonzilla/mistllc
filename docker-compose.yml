# --- MISTLLC Full Stack Compose ---
# Professional setup for Node.js backend + Vite frontend + FastAPI microservices + Redis + Nginx

services:
  # üß† Backend API (Node.js + Express / Cloudflare Worker adapter)
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: mistllc-backend
    ports:
      - "5000:5000"
    env_file:
      - .env
    depends_on:
      - redis
      - audio_service
      - ai_service
      - analytics_service
      - art_service
    networks:
      - mistllc_net

  # üé® Frontend (Vite + React/TypeScript)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: mistllc-frontend
    ports:
      - "5173:5173"
    environment:
      - NODE_ENV=development
    depends_on:
      - backend
    networks:
      - mistllc_net

  # üéß Phase 1 ‚Äî Audio Analysis Service
  audio_service:
    build:
      context: ./services/audio_service
      dockerfile: Dockerfile
    container_name: mistllc-audio
    command: ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8001"]
    ports:
      - "8001:8001"
    environment:
      - SERVICE_NAME=audio_service
      - API_KEY=${API_KEY}
    networks:
      - mistllc_net

  # ü§ñ Phase 2 ‚Äî AI Recommender
  ai_service:
    build:
      context: ./services/ai
      dockerfile: Dockerfile
    container_name: mistllc-ai
    command:
      ["uvicorn", "recommender:app", "--host", "0.0.0.0", "--port", "8002"]
    ports:
      - "8002:8002"
    environment:
      - SERVICE_NAME=ai_service
      - API_KEY=${API_KEY}
    networks:
      - mistllc_net

  # üìä Phase 3 ‚Äî Analytics / Reports
  analytics_service:
    build:
      context: ./services/analytics
      dockerfile: Dockerfile
    container_name: mistllc-analytics
    command: ["uvicorn", "report:app", "--host", "0.0.0.0", "--port", "8003"]
    ports:
      - "8003:8003"
    environment:
      - SERVICE_NAME=analytics_service
      - API_KEY=${API_KEY}
    networks:
      - mistllc_net

  # üñºÔ∏è Phase 4 ‚Äî Auto Art Generator (with Redis Worker)
  art_service:
    build:
      context: ./services/auto_art_service
      dockerfile: Dockerfile
    container_name: mistllc-art
    command: ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8004"]
    ports:
      - "8004:8004"
    environment:
      - SERVICE_NAME=art_service
      - REDIS_URL=redis://redis:6379/0
      - API_KEY=${API_KEY}
    depends_on:
      - redis
    networks:
      - mistllc_net

  # üî¥ Redis (queue broker for background jobs)
  redis:
    image: redis:7-alpine
    container_name: mistllc-redis
    ports:
      - "6379:6379"
    networks:
      - mistllc_net

  # üåê Nginx Reverse Proxy (optional, can route frontend/backend)
  nginx:
    image: nginx:stable-alpine
    container_name: mistllc-nginx
    depends_on:
      - frontend
      - backend
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    networks:
      - mistllc_net

networks:
  mistllc_net:
    driver: bridge
